!pip install roboflow
!pip install ultralytics

from roboflow import Roboflow
import os
import shutil
from collections import Counter
from ultralytics import YOLO, RTDETR
from shutil import copyfile
from google.colab import files

# load SafeWalkBD Dataset
rf = Roboflow(api_key=roboflow_api_key)
project = rf.workspace("safewalkbd").project("safewalkbd-l8jbn")
version = project.version(9)
dataset = version.download("yolov8")

# load Streets-and-Crosswalks Dataset
rf = Roboflow(api_key=roboflow_api_key)
project = rf.workspace("data-dynamos").project("streets-and-crosswalks")
version = project.version(42)
dataset = version.download("yolov8")

# SafeWalkBDì˜ class ID â†’ í†µí•© class ID
safewalkbd_map = {
    0: 0,    # Animal
    1: 6,    # Crosswalk
    2: 10,   # Obstacle
    3: 11,   # Over-bridge
    4: 12,   # Person
    5: 14,   # Pole
    6: 15,   # Pothole
    7: 16,   # Railway
    8: 17,   # Road-barrier
    9: 19,   # Sidewalk
    10: 20,  # Stairs
    11: 21,  # Traffic-light
    12: 22,  # Traffic-sign
    13: 23,  # Train
    14: 24,  # Tree
    15: 28,  # Vehicle
}

# StreetsAndCrosswalksì˜ class ID â†’ í†µí•© class ID
streets_map = {
    1: 1,    # bench
    2: 2,    # bike
    3: 3,    # bin
    4: 4,    # bush
    5: 4,    # bush- (í•©ì¹¨)
    6: 5,    # car
    7: 6,    # crosswalk
    8: 7,    # fence
    9: 8,    # minipole
    10: 9,   # miniwall
    11: 12,  # person
    12: 13,  # pinetree
    13: 14,  # pole
    14: 18,  # scooter
    15: 24,  # tree
    16: 25,  # truck
    17: 26,  # trunk
    18: 27,  # wall
}

def remap_labels(label_dir, id_map, drop_ids=None):
    for filename in os.listdir(label_dir):
        if filename.endswith('.txt'):
            file_path = os.path.join(label_dir, filename)
            with open(file_path, 'r') as f:
                lines = f.readlines()

            new_lines = []
            for line in lines:
                parts = line.strip().split()
                class_id = int(parts[0])

                if drop_ids and class_id in drop_ids:
                    continue  # drop_idsì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ëŠ” ê±´ë„ˆëœ€

                if class_id in id_map:
                    new_class_id = id_map[class_id]
                    new_line = f"{new_class_id} {' '.join(parts[1:])}\n"
                    new_lines.append(new_line)

            # ì¤„ì´ ì•„ì˜ˆ ì—†ì–´ë„ ë¹ˆ íŒŒì¼ë¡œ ë®ì–´ì”€ (YOLO í¬ë§·ì€ ë¹ˆ ë¼ë²¨ í—ˆìš©)
            with open(file_path, 'w') as f:
                f.writelines(new_lines)

remap_labels("/content/SafeWalkBD-9/train/labels", safewalkbd_map)
remap_labels("/content/SafeWalkBD-9/valid/labels", safewalkbd_map)
remap_labels("/content/SafeWalkBD-9/test/labels", safewalkbd_map)
remap_labels("/content/Streets-and-Crosswalks-42/train/labels", streets_map)
remap_labels("/content/Streets-and-Crosswalks-42/valid/labels", streets_map)
remap_labels("/content/Streets-and-Crosswalks-42/test/labels", streets_map)

src1 = "/content/SafeWalkBD-9"
src2 = "/content/Streets-and-Crosswalks-42"
dataset = "/content/dataset"

# ë³‘í•©í•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ ìƒì„±
for split in ['train', 'valid', 'test']:
    os.makedirs(f"{dataset}/images/{split}", exist_ok=True)
    os.makedirs(f"{dataset}/labels/{split}", exist_ok=True)

def merge_dataset(src, dst):
    for split in ['train', 'valid']:
        src_img = os.path.join(src, split, 'images')
        src_label = os.path.join(src, split, 'labels')
        dst_img = os.path.join(dst, 'images', split)
        dst_label = os.path.join(dst, 'labels', split)

        if os.path.exists(src_img):
            for f in os.listdir(src_img):
                shutil.copy(os.path.join(src_img, f), dst_img)

        if os.path.exists(src_label):
            for f in os.listdir(src_label):
                shutil.copy(os.path.join(src_label, f), dst_label)

# ì‹¤í–‰
merge_dataset(src1, dataset)
merge_dataset(src2, dataset)

yaml_text = """
train: /content/dataset/images/train
val: /content/dataset/images/valid
nc: 29
names: [
    'Animal', 'Bench', 'Bike', 'Bin', 'Bush', 'Car', 'Crosswalk',
    'Fence', 'Minipole', 'Miniwall', 'Obstacle', 'Over-bridge', 'Person', 'Pinetree',
    'Pole', 'Pothole', 'Railway', 'Road-barrier', 'Scooter', 'Sidewalk',
    'Stairs', 'Traffic-light', 'Traffic-sign', 'Train', 'Tree', 'Truck', 'Trunk', 'Vehicle',
    'Wall'
]
"""

with open("/content/dataset/data.yaml", "w") as f:
  f.write(yaml_text.strip())

!cat /content/dataset/data.yaml

# YOLO ë¼ë²¨ í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ê²½ë¡œ
label_path = "/content/dataset/labels/train"  # ë˜ëŠ” valid, test ë“±

label_count = Counter()

for label_file in os.listdir(label_path):
    if label_file.endswith(".txt"):
        with open(os.path.join(label_path, label_file), "r") as f:
            for line in f:
                class_id = line.strip().split()[0]  # ì²« ë²ˆì§¸ í•­ëª©ì´ í´ë˜ìŠ¤ ID
                label_count[int(class_id)] += 1

# ì¶œë ¥
print("ğŸ“Š í´ë˜ìŠ¤ë³„ ë¼ë²¨ ìˆ˜:")
for class_id, count in sorted(label_count.items()):
    print(f"í´ë˜ìŠ¤ {class_id}: {count}ê°œ")

from ultralytics import YOLO, RTDETR
import os
from shutil import copyfile

models = [
    ("YOLOv8n", YOLO("yolov8n.pt")),
    ("RT-DETR-l", RTDETR("rtdetr-l.pt"))
]

results_dict = {}

for name, model in models:
    print(f"ğŸ” {name} í•™ìŠµ ì‹œì‘...")
    try:
        # 1. í•™ìŠµ ì‹¤í–‰ (ê²€ìƒ‰ ê²°ê³¼ [2][4] ì°¸ì¡°)
        results = model.train(
            data="/content/dataset/data.yaml",
            epochs=1,
            imgsz=640,
            project="model_comparison",
            name=name,
            exist_ok=True,
            save=True,
            verbose=False
        )
        
        # 2. ë©”íŠ¸ë¦­ ì¶”ì¶œ ë°©ì‹ ìˆ˜ì • (ê²€ìƒ‰ ê²°ê³¼ [1][9] ì°¸ì¡°)
        if hasattr(model, "metrics"):
            metrics = model.metrics.box
            results_dict[name] = {
                "mAP50": metrics.map50,
                "mAP50-95": metrics.map,
                "precision": metrics.mp,
                "recall": metrics.mr
            }
            print(f"âœ… {name} ë©”íŠ¸ë¦­ ì¶”ì¶œ ì„±ê³µ")
            
            # 3. ì¦‰ì‹œ ëª¨ë¸ ì €ì¥ (ê²€ìƒ‰ ê²°ê³¼ [5] ì°¸ì¡°)
            save_dir = model.trainer.save_dir
            best_path = os.path.join(save_dir, 'weights', 'best.pt')
            last_path = os.path.join(save_dir, 'weights', 'last.pt')
            
            if os.path.exists(best_path):
                copyfile(best_path, f'{name}-optimized.pt')
            elif os.path.exists(last_path):  # best.pt ì—†ì„ ê²½ìš° last.pt ì‚¬ìš©
                copyfile(last_path, f'{name}-optimized.pt')
            print(f"ğŸ’¾ {name}-optimized.pt ì €ì¥ ì™„ë£Œ")
            
        else:
            print(f"âš ï¸ {name} ë©”íŠ¸ë¦­ ì •ë³´ ì—†ìŒ")

    except Exception as e:
        print(f"âš ï¸ {name} í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
        continue

# 4. ìµœì¢… ëª¨ë¸ ì„ íƒ (ê²€ìƒ‰ ê²°ê³¼ [3] ì°¸ì¡°)
if results_dict:
    best_model = max(results_dict, key=lambda x: results_dict[x]['mAP50-95'])
    print(f"\nğŸ”¥ ìµœì¢… ì„ íƒ ëª¨ë¸: {best_model} (mAP50-95: {results_dict[best_model]['mAP50-95']:.3f})")
else:
    print("""
    âŒ ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨. ë‹¤ìŒ ì‚¬í•­ í™•ì¸:
    1. CUDA ë©”ëª¨ë¦¬: !nvidia-smi â†’ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
    2. ë°ì´í„°ì…‹ ê²½ë¡œ: /content/dataset/data.yaml
    3. Ultralytics ë²„ì „: !pip install ultralytics==8.3.155
    """)

files.download('/content/model_comparison/RT-DETR-l/weights/best.pt')  # ì „ì²´ ê²½ë¡œ ì§€ì •
